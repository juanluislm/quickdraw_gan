{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# for deep learning: \n",
    "import keras\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Input, Dense, Conv2D, BatchNormalization, Dropout, Flatten\n",
    "from keras.layers import Activation, Reshape, Conv2DTranspose, UpSampling2D # new! \n",
    "from keras.optimizers import RMSprop\n",
    "\n",
    "# for plotting: \n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_images = \"../quickdraw_data/full_numpy_bitmap_banana.npy\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(307936, 784)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = np.load(input_images)\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(307936, 28, 28, 1)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = data/255\n",
    "data = np.reshape(data,(data.shape[0],28,28,1)) # fourth dimension is color\n",
    "img_w,img_h = data.shape[1:3]\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x13e2ece48>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAD/FJREFUeJzt3XuMVHWaxvHntVEwiOOFXoIXbC+gQYyMKXDjAHFlBTUCTryAxJFNzDCgCGM0Xtg/FmJicLPjCERRxsFBMzKujggxyg6SNTjGTCyMK6LuKtqj3KSJkmEiiQu8+0eXs632+VVbt1PN+/0kpKvrqZ/1WuHhVNWpU8fcXQDiOSLvAQDkg/IDQVF+ICjKDwRF+YGgKD8QFOUHgqL8QFCUHwiqTyPvbODAgd7W1tbIuwRCaW9v1549e6wnt62q/GZ2maTFklokPebui1K3b2trU7FYrOYuASQUCoUe37bip/1m1iLpIUmXSxou6XozG17pfw9AY1Xzmn+0pA/d/SN3/0rS7yRNqc1YAOqtmvKfLOnTLr9vK133DWY208yKZlbs6Oio4u4A1FLd3+139+XuXnD3Qmtra73vDkAPVVP+7ZJO7fL7KaXrAPQC1ZT/DUlDzex0MztK0jRJa2szFoB6q3hXn7sfMLM5kv5Dnbv6Vrj7lppN1ovs3bs3mW/cuDGZT5gwIZn369fve88ElFPVfn53f1HSizWaBUAD8fFeICjKDwRF+YGgKD8QFOUHgqL8QFANPZ6/N9u/f39mdv755yfXfvLJJ8l82rRpyXzVqlXJHKgEW34gKMoPBEX5gaAoPxAU5QeCovxAUOzq66G5c+dmZnv27Emuve+++5L5/Pnzk/nChQuT+bBhw5I50B22/EBQlB8IivIDQVF+ICjKDwRF+YGgKD8QFPv5S8p9vfZjjz2Wma1evTq5dtKkScn88ccfT+Z33XVXMi93/0B32PIDQVF+ICjKDwRF+YGgKD8QFOUHgqL8QFBV7ec3s3ZJ+yQdlHTA3Qu1GCoPixYtSubjxo3LzKZMmZJca2bJfMmSJcn88ssvT+bvv/9+ZnbOOeck1yKuWnzI5x/cPf1tFgCaDk/7gaCqLb9L+oOZbTKzmbUYCEBjVPu0f4y7bzezv5O03szed/dvfEi+9I/CTEkaMmRIlXcHoFaq2vK7+/bSz92SVksa3c1tlrt7wd0Lra2t1dwdgBqquPxm1t/MBnx9WdIESe/UajAA9VXN0/5BklaXdmP1kfSUu6+ryVQA6q7i8rv7R5LS56ZuInv37k3m69al/9165plnMrNy+/HLufTSS5N5uX31qeP916xZU9FMOPyxqw8IivIDQVF+ICjKDwRF+YGgKD8QVJiv7v7000+Tubsn89Gjv/PhxZppaWlJ5kuXLk3mqV2F7777bnLt8OHDkzkOX2z5gaAoPxAU5QeCovxAUJQfCIryA0FRfiCoMPv59+/fX9X6vn371miS7++SSy5J5uedd15mdvvttyfXvvTSSxXNhN6PLT8QFOUHgqL8QFCUHwiK8gNBUX4gKMoPBBVmP//BgwerWl/t13NX44gj0v9GP/jgg5nZ+PHjk2s3b96czFOfIUDvxpYfCIryA0FRfiAoyg8ERfmBoCg/EBTlB4Iqu5/fzFZIulLSbncfUbruBElPS2qT1C7pOnf/on5jVm/IkCFVrW9vb8/MWltbq/pvV+viiy/OzM4/P30W9Xnz5iXzDRs2JPM8P/+A6vRky/8bSZd967q7JW1w96GSNpR+B9CLlC2/u2+U9Pm3rp4iaWXp8kpJV9V4LgB1Vulr/kHuvrN0eZekQTWaB0CDVP2Gn3ee5C7zRHdmNtPMimZW7OjoqPbuANRIpeX/zMwGS1Lp5+6sG7r7cncvuHsh7zfGAPy/Ssu/VtKM0uUZktbUZhwAjVK2/Ga2StLrks42s21mdpOkRZIuNbMPJP1j6XcAvUjZ/fzufn1GlD5QvMkMGpR+T/LII49M5sViMTMbNWpURTPVSup4/8WLFyfXpj4jIEmvv/56Mr/ooouSOZoXn/ADgqL8QFCUHwiK8gNBUX4gKMoPBBXmq7v79En/r44ePTqZv/baa5nZ7NmzK5qpEcaOHZvMJ0+eXFW+devWZP6DH/wgmSM/bPmBoCg/EBTlB4Ki/EBQlB8IivIDQVF+IKgw+/nLueGGG5L5rbfempktW7YsuXbAgAEVzVQL5U7v/eSTTybzYcOGJfNrrrkmma9bty4za2lpSa5FfbHlB4Ki/EBQlB8IivIDQVF+ICjKDwRF+YGg2M9fMn369GQ+Z86czGz16tXJtTfeeGNFMzXCsccem8xT++kl6YILLkjmS5Ysycxuu+225FrUF1t+ICjKDwRF+YGgKD8QFOUHgqL8QFCUHwiq7H5+M1sh6UpJu919ROm6BZJ+KqmjdLP57v5ivYZshHL7u1PHrd9///3JteW+K6DcMfd5GjlyZDJfuHBhMr/jjjsysy+//DK5dtasWcn8xBNPTOZI68nfut9Iuqyb63/p7iNLf3p18YGIypbf3TdK+rwBswBooGqeb84xs7fNbIWZHV+ziQA0RKXlXybpTEkjJe2U9IusG5rZTDMrmlmxo6Mj62YAGqyi8rv7Z+5+0N0PSfqVpMyzXLr7cncvuHuhtbW10jkB1FhF5TezwV1+/bGkd2ozDoBG6cmuvlWSLpY00My2SfoXSReb2UhJLqld0s/qOCOAOjB3b9idFQoFLxaLDbu/WtqyZUtmNmLEiOTatWvXJvNJkyZVNFMzOHDgQDIfP358ZrZx48bk2ptvvjmZP/TQQ8k8okKhoGKxaD25bfN+ugRAXVF+ICjKDwRF+YGgKD8QFOUHguKru3vo3HPPzcymTp2aXDt79uxkPnHixGR+1FFHJfM89emT/iv0wgsvZGaTJ09Orn300UeT+ZgxY5L5tGnTMjOzHu0NO6yx5QeCovxAUJQfCIryA0FRfiAoyg8ERfmBoDiktwa2bduWzE877bRkvmzZsmQ+c+bM7z1Tb/DFF18k84EDBybzQ4cOJfNCoZCZTZgwIbk29bkOSbr66quTed++fZN5vXBIL4CyKD8QFOUHgqL8QFCUHwiK8gNBUX4gKI7nr4FTTjklmd9yyy3J/M4770zm06dPT+bHHHNMMm9Wxx+fPsXjtddem8yfe+65ZH7GGWdkZk899VRybbnPbowenXmSKknSWWedlcybAVt+ICjKDwRF+YGgKD8QFOUHgqL8QFCUHwiq7PH8ZnaqpCckDZLkkpa7+2IzO0HS05LaJLVLus7dkwdoH67H85ezd+/eZN7W1pbMx44dm8yff/75zKylpSW5tpm9+uqryXzcuHHJfMeOHZnZ4MGDk2t70ItknpdaH89/QNLt7j5c0t9LusXMhku6W9IGdx8qaUPpdwC9RNnyu/tOd3+zdHmfpPcknSxpiqSVpZutlHRVvYYEUHvf6zW/mbVJ+qGkP0ka5O47S9Eudb4sANBL9Lj8ZnaMpN9L+rm7/6Vr5p0vkLp9kWRmM82saGbFjo6OqoYFUDs9Kr+ZHanO4v/W3b8+muIzMxtcygdL2t3dWndf7u4Fdy+0trbWYmYANVC2/Nb5tuavJb3n7g90idZKmlG6PEPSmtqPB6BeenJI748k/UTSZjN7q3TdfEmLJP27md0k6c+SrqvPiL3fcccdl8zXr1+fzC+88MJkvmDBgszs3nvvTa5tZiNHjqxq/aZNmzKzK6+8Mrm2WXfl1VLZ8rv7HyVlPRLjazsOgEbhE35AUJQfCIryA0FRfiAoyg8ERfmBoPjq7iYwatSoZP7www8n89mzZ2dm/fr1S6695557kvkRR+S3fRgwYEAyT301tyS98sormVm5/fwRsOUHgqL8QFCUHwiK8gNBUX4gKMoPBEX5gaDYz98LzJo1K5l/9dVXmdm8efOSa7du3ZrMH3jggWRe7rsK6mnixInJ/OWXX27QJL0TW34gKMoPBEX5gaAoPxAU5QeCovxAUJQfCIr9/IeBuXPnZmZnn312cu1VV6XPr7py5cpkPnXq1GSe2hd/+umnJ9eedNJJybzc8fyPPPJIZrZ///7k2qOPPjqZHw7Y8gNBUX4gKMoPBEX5gaAoPxAU5QeCovxAUGX385vZqZKekDRIkkta7u6LzWyBpJ9K6ijddL67v1ivQVGZcse879mzJ5k/++yzyXzp0qXJ/Omnn87MDh06lFxbTx9//HEyHz58eIMmyU9PPuRzQNLt7v6mmQ2QtMnM1peyX7r7v9VvPAD1Urb87r5T0s7S5X1m9p6kk+s9GID6+l6v+c2sTdIPJf2pdNUcM3vbzFaY2fEZa2aaWdHMih0dHd3dBEAOelx+MztG0u8l/dzd/yJpmaQzJY1U5zODX3S3zt2Xu3vB3Qutra01GBlALfSo/GZ2pDqL/1t3f06S3P0zdz/o7ock/UrS6PqNCaDWypbfzEzSryW95+4PdLl+cJeb/VjSO7UfD0C99OTd/h9J+omkzWb2Vum6+ZKuN7OR6tz91y7pZ3WZEHXVv3//ZD5jxoyq8oMHD2Zm+/btS64t9x7Rjh07kvmuXbsyszPPPDO5NoKevNv/R0nWTcQ+faAX4xN+QFCUHwiK8gNBUX4gKMoPBEX5gaD46m7UVUtLS2ZW7vTe5fKhQ4dWNBM6seUHgqL8QFCUHwiK8gNBUX4gKMoPBEX5gaDM3Rt3Z2Ydkv7c5aqBktLfHZ2fZp2tWeeSmK1StZztNHfv0fflNbT837lzs6K7F3IbIKFZZ2vWuSRmq1Res/G0HwiK8gNB5V3+5Tnff0qzztasc0nMVqlcZsv1NT+A/OS95QeQk1zKb2aXmdl/m9mHZnZ3HjNkMbN2M9tsZm+ZWTHnWVaY2W4ze6fLdSeY2Xoz+6D0s9vTpOU02wIz21567N4ysytymu1UM/tPM3vXzLaY2bzS9bk+dom5cnncGv6038xaJP2PpEslbZP0hqTr3f3dhg6SwczaJRXcPfd9wmY2TtJfJT3h7iNK1/2rpM/dfVHpH87j3f2uJpltgaS/5n3m5tIJZQZ3PbO0pKsk/ZNyfOwSc12nHB63PLb8oyV96O4fuftXkn4naUoOczQ9d98o6fNvXT1F0srS5ZXq/MvTcBmzNQV33+nub5Yu75P09Zmlc33sEnPlIo/ynyzp0y6/b1NznfLbJf3BzDaZ2cy8h+nGoNJp0yVpl6RBeQ7TjbJnbm6kb51Zumkeu0rOeF1rvOH3XWPc/QJJl0u6pfT0til552u2Ztpd06MzNzdKN2eW/ps8H7tKz3hda3mUf7ukU7v8fkrpuqbg7ttLP3dLWq3mO/vwZ1+fJLX0c3fO8/xNM525ubszS6sJHrtmOuN1HuV/Q9JQMzvdzI6SNE3S2hzm+A4z6196I0Zm1l/SBDXf2YfXSvr67JgzJK3JcZZvaJYzN2edWVo5P3ZNd8Zrd2/4H0lXqPMd/62S/jmPGTLmOkPSf5X+bMl7Nkmr1Pk08H/V+d7ITZJOlLRB0geSXpZ0QhPN9qSkzZLeVmfRBuc02xh1PqV/W9JbpT9X5P3YJebK5XHjE35AULzhBwRF+YGgKD8QFOUHgqL8QFCUHwiK8gNBUX4gqP8DVJuqZ+WyOdgAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(data[4242,:,:,0], cmap='Greys')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def discriminator_builder(depth=64,p=0.4):\n",
    "\n",
    "    # Define inputs\n",
    "    inputs = Input((img_w,img_h,1))\n",
    "    \n",
    "    # Convolutional layers\n",
    "    conv1 = Conv2D(depth*1, 5, strides=2, padding='same', activation='relu')(inputs)\n",
    "    conv1 = Dropout(p)(conv1)\n",
    "    \n",
    "    conv2 = Conv2D(depth*2, 5, strides=2, padding='same', activation='relu')(conv1)\n",
    "    conv2 = Dropout(p)(conv2)\n",
    "    \n",
    "    conv3 = Conv2D(depth*4, 5, strides=2, padding='same', activation='relu')(conv2)\n",
    "    conv3 = Dropout(p)(conv3)\n",
    "    \n",
    "    conv4 = Conv2D(depth*8, 5, strides=1, padding='same', activation='relu')(conv3)\n",
    "    conv4 = Flatten()(Dropout(p)(conv4))\n",
    "    \n",
    "    # Output layer\n",
    "    output = Dense(1, activation='sigmoid')(conv4)\n",
    "    \n",
    "    # Model definition\n",
    "    model = Model(inputs=inputs, outputs=output)\n",
    "    model.summary()\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 28, 28, 1)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 14, 14, 64)        1664      \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 14, 14, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 7, 7, 128)         204928    \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 7, 7, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 4, 4, 256)         819456    \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 4, 4, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 4, 4, 512)         3277312   \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 4, 4, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 8192)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 8193      \n",
      "=================================================================\n",
      "Total params: 4,311,553\n",
      "Trainable params: 4,311,553\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "discriminator = discriminator_builder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "discriminator.compile(loss='binary_crossentropy', \n",
    "                      optimizer=RMSprop(lr=0.0008, decay=6e-8, clipvalue=1.0), \n",
    "                      metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def generator_builder(z_dim=100,depth=64,p=0.4):\n",
    "    \n",
    "    # Define inputs\n",
    "    inputs = Input((z_dim,))\n",
    "    \n",
    "    # First dense layer\n",
    "    dense1 = Dense(7*7*64)(inputs)\n",
    "    dense1 = BatchNormalization(momentum=0.9)(dense1) # default momentum for moving average is 0.99\n",
    "    dense1 = Activation(activation='relu')(dense1)\n",
    "    dense1 = Reshape((7,7,64))(dense1)\n",
    "    dense1 = Dropout(p)(dense1)\n",
    "    \n",
    "    # De-Convolutional layers\n",
    "    conv1 = UpSampling2D()(dense1)\n",
    "    conv1 = Conv2DTranspose(int(depth/2), kernel_size=5, padding='same', activation=None,)(conv1)\n",
    "    conv1 = BatchNormalization(momentum=0.9)(conv1)\n",
    "    conv1 = Activation(activation='relu')(conv1)\n",
    "    \n",
    "    conv2 = UpSampling2D()(conv1)\n",
    "    conv2 = Conv2DTranspose(int(depth/4), kernel_size=5, padding='same', activation=None,)(conv2)\n",
    "    conv2 = BatchNormalization(momentum=0.9)(conv2)\n",
    "    conv2 = Activation(activation='relu')(conv2)\n",
    "    \n",
    "    conv3 = Conv2DTranspose(int(depth/8), kernel_size=5, padding='same', activation=None,)(conv2)\n",
    "    conv3 = BatchNormalization(momentum=0.9)(conv3)\n",
    "    conv3 = Activation(activation='relu')(conv3)\n",
    "\n",
    "    # Output layer\n",
    "    output = Conv2D(1, kernel_size=5, padding='same', activation='sigmoid')(conv3)\n",
    "\n",
    "    # Model definition    \n",
    "    model = Model(inputs=inputs, outputs=output)\n",
    "    model.summary()\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 3136)              316736    \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 3136)              12544     \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 3136)              0         \n",
      "_________________________________________________________________\n",
      "reshape_1 (Reshape)          (None, 7, 7, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 7, 7, 64)          0         \n",
      "_________________________________________________________________\n",
      "up_sampling2d_1 (UpSampling2 (None, 14, 14, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_1 (Conv2DTr (None, 14, 14, 32)        51232     \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 14, 14, 32)        128       \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "up_sampling2d_2 (UpSampling2 (None, 28, 28, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_2 (Conv2DTr (None, 28, 28, 16)        12816     \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 28, 28, 16)        64        \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 28, 28, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_3 (Conv2DTr (None, 28, 28, 8)         3208      \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 28, 28, 8)         32        \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 28, 28, 8)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 28, 28, 1)         201       \n",
      "=================================================================\n",
      "Total params: 396,961\n",
      "Trainable params: 390,577\n",
      "Non-trainable params: 6,384\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "generator = generator_builder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def adversarial_builder(z_dim=100):\n",
    "    model = Sequential()\n",
    "    model.add(generator)\n",
    "    model.add(discriminator)\n",
    "    model.compile(loss='binary_crossentropy', \n",
    "                  optimizer=RMSprop(lr=0.0004, decay=3e-8, clipvalue=1.0), \n",
    "                  metrics=['accuracy'])\n",
    "    model.summary()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "model_2 (Model)              (None, 28, 28, 1)         396961    \n",
      "_________________________________________________________________\n",
      "model_1 (Model)              (None, 1)                 4311553   \n",
      "=================================================================\n",
      "Total params: 4,708,514\n",
      "Trainable params: 4,702,130\n",
      "Non-trainable params: 6,384\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "adversarial_model = adversarial_builder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_trainable(net, val):\n",
    "    net.trainable = val\n",
    "    for l in net.layers:\n",
    "        l.trainable = val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epochs=2000,batch=128):\n",
    "    \n",
    "    d_metrics = []\n",
    "    a_metrics = []\n",
    "    \n",
    "    running_d_loss = 0\n",
    "    running_d_acc = 0\n",
    "    running_a_loss = 0\n",
    "    running_a_acc = 0\n",
    "    \n",
    "    for i in range(epochs):\n",
    "        \n",
    "        if i%100 == 0:\n",
    "            print(i)\n",
    "        \n",
    "        real_imgs = np.reshape(data[np.random.choice(data.shape[0],batch,replace=False)],(batch,28,28,1))\n",
    "        fake_imgs = generator.predict(np.random.uniform(-1.0, 1.0, size=[batch, 100]))\n",
    "\n",
    "        x = np.concatenate((real_imgs,fake_imgs))\n",
    "        y = np.ones([2*batch,1])\n",
    "        y[batch:,:] = 0\n",
    "        \n",
    "        make_trainable(discriminator, True)\n",
    "        \n",
    "        d_metrics.append(discriminator.train_on_batch(x,y))\n",
    "        running_d_loss += d_metrics[-1][0]\n",
    "        running_d_acc += d_metrics[-1][1]\n",
    "        \n",
    "        make_trainable(discriminator, False)\n",
    "        \n",
    "        noise = np.random.uniform(-1.0, 1.0, size=[batch, 100])\n",
    "        y = np.ones([batch,1])\n",
    "\n",
    "        a_metrics.append(adversarial_model.train_on_batch(noise,y)) \n",
    "        running_a_loss += a_metrics[-1][0]\n",
    "        running_a_acc += a_metrics[-1][1]\n",
    "        \n",
    "        if (i+1)%500 == 0:\n",
    "\n",
    "            print('Epoch #{}'.format(i+1))\n",
    "            log_mesg = \"%d: [D loss: %f, acc: %f]\" % (i, running_d_loss/i, running_d_acc/i)\n",
    "            log_mesg = \"%s  [A loss: %f, acc: %f]\" % (log_mesg, running_a_loss/i, running_a_acc/i)\n",
    "            print(log_mesg)\n",
    "\n",
    "            noise = np.random.uniform(-1.0, 1.0, size=[16, 100])\n",
    "            gen_imgs = generator.predict(noise)\n",
    "\n",
    "            plt.figure(figsize=(5,5))\n",
    "\n",
    "            for k in range(gen_imgs.shape[0]):\n",
    "                plt.subplot(4, 4, k+1)\n",
    "                plt.imshow(gen_imgs[k, :, :, 0], cmap='gray')\n",
    "                plt.axis('off')\n",
    "                \n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "    \n",
    "    return a_metrics, d_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "100\n"
     ]
    }
   ],
   "source": [
    "a_metrics_complete, d_metrics_complete = train(epochs=3000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
